---
title: "Working with datasets in R and the {tidyverse}"
subtitle: "Summarising data with {dplyr}"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: true
date: "27th May 2021"
editor_options: 
  chunk_output_type: inline
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

> **Questions**
>
> How can I create summary tables of my data?
>
<!-- > How do I format my data so I get the tidy summaries? -->
<!-- > -->
> **Objectives**
>
> To be able to understand how to group data to create convenient summaries.
<!-- > -->
<!-- > To be able to reshape data to create convenient summaries. -->
<!-- > -->
<!-- > To be able to apply multiple functions to a single summary call to create complex summaries quickly. -->


# R projects

If you have not worked with a similar program like R before, the notion of _where the program runs from_ is an unfamiliar one. We never really think about where SPSS or excel is running from, we have a file open and work on it. but hopefully, you know where the file is being saved? This is basically where your program is running from. We call this "the working directory". In R, this concept is important for when reading in os saving (writing) files out from R.

The difference in R is that where R is running and where you save, for instance your script, are _not_ necessarily the same thing. And this can be confusing and lead to difficulties in managing your analysis project. We have ways of setting this working directory for R, but the absolutely best way to manage your project, is to utilise Rprojects! Rprojects set your working directory for you, and RStudio makes it easy to open your projects and begin where you left off last. Cleverly organised Rprojects are on of the best ways to ensure reproducibility in R.

Let us create an Rproject for this course. When you maybe start you analysis project later, create a new one and start fresh!

Create a project by going to 
File -> New Project ... -> New directory -> New project 

Select the main directory you want to create your project in, and give the new folder a name, like "swc_tidyverse". Click "Create project".

RStudio will restart in a fresh instance. Notice where the breadcrumbs in the navigation in the Files pane in RStudio. You should be able to recognise the file path to what you specified in the gui.

For you projects we recommend structuring your projects in a clear fashion. Some guiding rules:

- `data/` to keep all your raw data. To be read from, never written to.
- `ouput` to keep your analysis results. To be written to and treated like disposable. Your results should be reproducible by your scripts.
- `scripts` where you place your scripts, i.e. files with R code running your data handling and analyses.

For instance, if you place your input data in `data/my_data.csv`, in your processing script saved in `scripts/linear_models.R`, and you have started RStudio by opening your project, you can read in the data with:

```{r eval = FALSE}
library(tidyverse)
my_data <- read_csv("data/my_data.csv")
```

This is called a _relative path_ because the path to your data is _relative_ to where your working directory is. And your working directory is the folder where the `my_project.Rproject` file is. 

We can also check the working directory in the console to be sure

```{r eval = FALSE}
getwd()
```

Rprojects are also great if you ever need to share your entire workflow with a colleague. If you are only using relative paths in your project, and all your scripts are safely stored in the project, giving your colleague the entire project folder should work without extra effort other than them installing the necessary packages you have used in your scripts.

# **Rproject, challenges.** {.tabset}
## Assignment

Room: plenary  
Duration: 5 minutes

>
> **1** Close RStudio. Find the `.Rproject` file in the folder you made before for this project (i.e. navigate to the folder you made). Double click it. Did RStudio open your project for you? 
>

## Solution

- Double clicking `.Rproject` files will open them in RStudio.  
- If you dont remember exactly where you put your project, try looking for it in `Files -> Recent projects`. This is the list of your most recently used projects. Hopefully it is in that list!


# Data summaries

Next to visualizing data, creating summaries of the data in tables is a quick way to get an idea of what type of data you have at hand. It might help you spot incorrect data or extreme values, or whether specific analysis approaches are needed.

To summarize data with the {tidyverse} efficiently, we need to utilize the tools we have learned the previous days, like adding new variables, tidy-selections, pivots and grouping data. All these tools combine amazingly when we start making summaries. 

Let us start from the beginning with summaries, and work our way up to the more complex variations as we go.

First, we must again prepare our workspace with our packages and data.

```{r}
library(tidyverse)
penguins <- palmerpenguins::penguins
```

We should start to feel quite familiar with our penguins by now. Let us start by finding the mean of the bill length

```{r}
penguins %>% 
  summarise(bill_length_mean = mean(bill_length_mm))
```

`NA`. as we remember, there are some `NA` values in our data. We can omit these by adding the `na.rm = TRUE` argument, which will remove all `NA`'s before calculating the mean.

```{r}
penguins %>% 
  summarise(bill_length_mean = mean(bill_length_mm, na.rm = TRUE))
```

An alternative way to remove missing values from a column is to pass the column to {tidyr}'s `drop_na()` function. 

```{r}
penguins %>% 
  drop_na(bill_length_mm) %>% 
  summarise(bill_length_mean = mean(bill_length_mm))
```


```{r}
penguins %>% 
  drop_na(bill_length_mm) %>% 
  summarise(bill_length_mean = mean(bill_length_mm),
            bill_length_min = min(bill_length_mm),
            bill_length_max = max(bill_length_mm))
```

# **Data summaries, challenges.** {.tabset}
## Assignment

Room: break-out  
Duration: 10 minutes

>
> **1a**: First start by trying to summarise a single column, `body_mass_g`, by calculating its mean in *kilograms*.
>
> **1b**: Add a column with the standard deviation of `body_mass_g` on *kilogram* scale.
>
> **1c**: Now add the same two metrics for `flipper_length_mm` on *centimeter* scale and give the columns clear names. Why could the `drop_na()` step give us wrong results? 
>

## Solution

```{r "solutions-1"}
## 1a
penguins %>% 
  drop_na(body_mass_g) %>% 
  summarise(body_mass_kg_mean = mean(body_mass_g / 1000))

# 1b
penguins %>% 
  drop_na(body_mass_g) %>% 
  summarise(body_mass_kg_mean = mean(body_mass_g / 1000),
            body_mass_kg_sd = sd(body_mass_g / 1000))

## 1c 
penguins %>% 
  summarise(body_mass_kg_mean      = mean(body_mass_g / 1000, na.rm = TRUE),
            body_mass_kg_sd        = sd(body_mass_g / 1000, na.rm = TRUE),
            flipper_length_cm_mean = mean(flipper_length_mm / 10, na.rm = TRUE),
            flipper_length_cm_sd   = sd(flipper_length_mm / 10, na.rm = TRUE))

penguins %>% 
  drop_na(body_mass_g, flipper_length_mm) %>% 
  summarise(body_mass_kg_mean      = mean(body_mass_g / 1000),
            body_mass_kg_sd        = sd(body_mass_g / 1000),
            flipper_length_cm_mean = mean(flipper_length_mm / 10),
            flipper_length_cm_sd   = sd(flipper_length_mm / 10))
```

Here, we also added some extra space after the column names, to align the functions up.
This is a fairly common coding practice for this type of code, that usually makes it easier for others to read.

<!-- # Summarising multiple columns -->

<!-- We've already mentioned that `summarize()` accepts arguments much like `mutate()` does. Which means that it might also work with across? That would be convenient when we'd like to summarize across many columns at once.  -->

<!-- ```{r} -->
<!-- penguins %>%  -->
<!--   summarise(across(.cols = starts_with("bill"), -->
<!--                    .fns = mean)) -->
<!-- ``` -->

<!-- We still have the problem with `NA`s. But, we can use the `...` argument! -->

<!-- ```{r} -->
<!-- penguins %>%  -->
<!--   summarise(across(.cols = starts_with("bill"), -->
<!--                    .fns = mean,  -->
<!--                    na.rm = TRUE)) -->
<!-- ``` -->

<!-- The name of the columns are a little unsatisfactory though, they give us no real indication of what the metric is. We can add names , but we'll need to place the function inside a `list()` first.  -->

<!-- ```{r} -->
<!-- penguins %>%  -->
<!--   summarise(across(.cols = starts_with("bill"), -->
<!--                    .fns = list("mean" = mean), -->
<!--                    na.rm = TRUE)) -->
<!-- ``` -->

<!-- And like with `across()` before, we can control how the column names are made by the use of the `.names` argument and knowing the internal placeholders for the names of the columns (`{.col}`) and the functions (`{.fn}`). -->

<!-- ```{r} -->
<!-- penguins %>%  -->
<!--   summarise(across(.cols = starts_with("bill"), -->
<!--                    .fns = list("mean" = mean, -->
<!--                                "sd" = sd), -->
<!--                    na.rm = TRUE, -->
<!--                    .names = "{.fn}_{.col}")) -->
<!-- ``` -->

<!-- Now we know how to summarize several columns at once, and we can even do that with several functions. The last examples we saw, are actually a little over-complicated, because we wanted to make sure you got a feel for how things work. Notice how all the functions we are using take the `na.rm = TRUE` argument to remove NA. This consistency across the three functions makes is possible to let `across()` know in one line that all the functions should use this setting. -->

<!-- ```{r} -->
<!-- penguins %>%  -->
<!--   summarise(across(.cols = ends_with("mm") | ends_with("g"),  -->
<!--                    .fns = list("mean" = mean, -->
<!--                                "sd" = sd),  -->
<!--                    na.rm = TRUE)) -->
<!-- ``` -->

<!-- But remember, this trick only works when using functions that have this same argument in them, and not all functions do. -->



<!-- # **Summarizing multiple columns, challenges.** {.tabset} -->
<!-- ## Assignment -->

<!-- Room: break-out   -->
<!-- Duration: 10 minutes   -->

<!-- > -->
<!-- > **2a**: Calculate the mean of all columns containing an underscore ("_") -->
<!-- > -->
<!-- > **2b**: Calculate the mean, minimum and maximum of all columns containing an underscore ("_") -->

<!-- ## Solution -->

<!-- ```{r "solutions-2"} -->
<!-- ## 2a -->
<!-- penguins %>%  -->
<!--   summarise(across(.cols = contains("_"),  -->
<!--                    .fns = mean, -->
<!--                    na.rm = TRUE)) -->

<!-- # 2b -->
<!-- penguins %>%  -->
<!--   summarise(across(.cols = contains("_"),  -->
<!--                    .fns = list("mean" = mean, -->
<!--                                "min" = min, -->
<!--                                "max" = max),  -->
<!--                    na.rm = TRUE)) -->

<!-- ``` -->


# Summarising grouped data

All the examples we have gone through so far with summarizing data, we have summarized the entire data set. But most times, we want to have a look at groups in our data, and summarize based on these groups. How can we manage to summarize while preserving grouping information?

We've already worked a little with the `group_by()` function, and we will use it again! Because, once we know how to summarize data, summarizing data by groups is as simple as adding one more line to our code.

Let us start with our first example of getting the mean of a single column.

```{r}
penguins %>% 
  drop_na(body_mass_g) %>% 
  summarise(body_mass_g_mean = mean(body_mass_g))
```

Here, we are getting a single mean for the entire data set. In order to get, for instance the means of each of the species, we can group by species before we summarize.

```{r}
penguins %>% 
  drop_na(body_mass_g) %>% 
  group_by(species) %>% 
  summarise(body_mass_kg_mean = mean(body_mass_g / 1000))
```

And now we suddenly have three means! And they are tidily collected in each their row.
To this we can keep adding as we did before.

```{r}
penguins %>% 
  drop_na(body_mass_g) %>% 
  group_by(species) %>%
  summarise(body_mass_kg_mean = mean(body_mass_g / 1000),
            body_mass_kg_min = min(body_mass_g / 1000),
            body_mass_kg_max = max(body_mass_g / 1000))
```

Now we are suddenly able to easily compare groups within our data, since they are so neatly summarized here. 

# Ungrouping for future control

We've been grouping a lot and not ungrouping. Which might seem fine now, because we have not really done anything more after the summarize. But in many cases we might continue our merry data handling way and do lots more, and then the preserving of the grouping can give us some unexpected results. Let us explore that a little.

```{r}
penguins %>% 
  group_by(species) %>% 
  summarise(records = n())
```

When we group by a single column and summarize, the output data is no longer grouped. In a way, the `summarize()` uses up one group while summarizing, as based on species, the data can not be condensed any further than this.

```{r}
penguins %>% 
  group_by(species, island) %>% 
  summarise(records = n())
```

When we group by two columns, it actually has the same behavior. But because we used to have two groups, we now are left with one. In this case "species" is still a  grouping variable. Lets say we want a column now, that counts the total number of penguins observations. That would be the sum of the "n" column.

```{r}
penguins %>% 
  group_by(species, island) %>% 
  summarise(records = n()) %>% 
  mutate(total = sum(records))
```

But that is not what we are expecting! why? Because the data is still grouped by species, it is now taking the sum within each species, rather than the whole. To get the whole we need first to `ungroup()`, and then try again.

```{r}
penguins %>% 
  group_by(species, island) %>% 
  summarise(records = n()) %>% 
  ungroup() %>% 
  mutate(total = sum(records))
```

